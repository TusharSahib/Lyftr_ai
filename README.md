# ğŸš€ Lyftr AI â€“ Full-Stack Web Scraper

**Lyftr AI** is a universal full-stack web scraper (MVP) that intelligently extracts structured content from modern websites â€” including JavaScript-rendered pages â€” and presents the results in a clean, interactive React UI.

It supports static scraping, Playwright-based rendering, user-like interactions (clicks, scrolls, pagination), and exports a schema-compliant JSON output.

---

## âœ¨ Key Features

- âœ… **Dual-mode scraping**
  - Static HTML scraping (BeautifulSoup)
  - JavaScript rendering with Playwright (auto fallback)

- âœ… **Smart section detection**
  - Semantic landmarks (`header`, `main`, `section`, `footer`)
  - Heading-based grouping (`h1`â€“`h3`)
  - Auto-labeling & type classification

- âœ… **Advanced interactions**
  - Tabs & buttons
  - â€œLoad Moreâ€ handling
  - Pagination
  - Infinite scroll (configurable depth)

- âœ… **Multi-page scraping**
  - Depth â‰¥ 3 with safe navigation

- âœ… **Noise filtering**
  - Cookie banners
  - Modals & overlays
  - Ads & tracking scripts

- âœ… **Schema-compliant JSON output**
  - Matches assignment specification exactly

- âœ… **Modern frontend**
  - React + Vite SPA
  - Accordion-based section viewer
  - Downloadable JSON

- âœ… **Production-ready**
  - Timeouts
  - Graceful error handling
  - Partial failure tolerance

---

## ğŸ§° Tech Stack

### Backend
- **Python 3.10+**
- **FastAPI**
- **Playwright**
- **BeautifulSoup**
- **Pydantic**

### Frontend
- **React**
- **Vite**
- **Axios**
- **Modern CSS**

---

## ğŸš€ Quick Start (Recommended)

### Prerequisites
- Python **3.10+**
- Node.js **18+**
- ~2GB disk space (Playwright browsers)

``bash
chmod +x run.sh
./run.sh
Server starts at:

dts
Copy code
http://localhost:8000
ğŸ›  Manual Setup (If run.sh fails)
Backend
bash
Copy code
python -m venv venv
source venv/bin/activate

pip install -r requirements.txt
python -m playwright install chromium

uvicorn main:app --host 0.0.0.0 --port 8000
Frontend
bash
Copy code
cd frontend
npm install
npm run build
cd ..
ğŸ–¥ï¸ Usage
Web Interface
Open http://localhost:8000

Enter a website URL

Click Scrape

View extracted sections

Expand sections to inspect JSON

Download full JSON result

ğŸ”Œ API Endpoints
Health Check
bash
Copy code
curl http://localhost:8000/healthz
json
Copy code
{
  "status": "ok",
  "version": "1.0.0"
}
Scrape URL
bash
Copy code
curl -X POST http://localhost:8000/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
Response (simplified)
json
Copy code
{
  "result": {
    "url": "https://example.com",
    "scrapedAt": "2025-12-28T23:02:00Z",
    "meta": {
      "title": "...",
      "description": "...",
      "language": "en",
      "canonical": null
    },
    "sections": [],
    "interactions": {
      "clicks": [],
      "scrolls": 0,
      "pages": []
    },
    "errors": []
  }
}
ğŸŒ Recommended Test URLs
Static Content
https://en.wikipedia.org/wiki/Artificial_intelligence

https://developer.mozilla.org/en-US/docs/Web/JavaScript

JavaScript-Rendered
https://vercel.com

https://nextjs.org/docs

Pagination / Infinite Scroll
https://news.ycombinator.com

https://dev.to/t/javascript

https://unsplash.com/s/photos/nature

ğŸ“ Project Structure
stylus
Copy code
.
â”œâ”€â”€ run.sh
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ design_notes.md
â”œâ”€â”€ capabilities.json
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ static_scraper.py
â”‚   â”œâ”€â”€ js_scraper.py
â”‚   â”œâ”€â”€ section_parser.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â””â”€â”€ dist/
ğŸ§  Key Design Decisions
Static vs JS Rendering
First attempt: static HTML fetch

Fallback to Playwright if:

Content < 500 chars

Key selectors missing

Section Detection
Semantic landmarks

Heading hierarchy

Auto-generated labels

Section type inference (hero, faq, grid, etc.)

Interaction Strategy
Tabs: [role="tab"]

Load more: text matching

Pagination: numbered / â€œNextâ€

Infinite scroll: max 3 cycles

âš ï¸ Limitations
âŒ Cloudflare-protected sites

âŒ Login-required sites

âŒ Video-only content

âŒ Cross-domain crawling

âš¡ Performance Notes
First run: ~3â€“5 seconds

Subsequent runs: ~1â€“3 seconds

Memory usage: ~200MB

Safe concurrency: ~5 scrapes

ğŸ§© Environment Variables (Optional)
env
Copy code
SCRAPE_TIMEOUT=60
MAX_SCROLL_DEPTH=3
JS_RENDER_THRESHOLD=500
HEADLESS=true
ğŸ§ª Development Mode
Backend (hot reload)
bash
Copy code
uvicorn main:app --reload
Frontend (dev server)
bash
Copy code
cd frontend
npm run dev
Visit:
http://localhost:5173

ğŸ“Œ Submission Info
Created: December 2025

Author: Tushar Goyal

Language: Python + React

Assignment: Full-Stack Web Scraper

âœ… Capabilities Summary
See capabilities.json for the full feature checklist.

ğŸ“„ License
This project is provided for educational and evaluation purposes.
